{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:40:13.699001Z",
     "start_time": "2020-05-01T13:40:13.696610Z"
    }
   },
   "outputs": [],
   "source": [
    "# !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# !wget --directory-prefix=/content -q http://apache.osuosl.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
    "# !wget --directory-prefix=/content -q http://apache.osuosl.org/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
    "# !tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
    "# !pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:40:13.935302Z",
     "start_time": "2020-05-01T13:40:13.930103Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import findspark\n",
    "\n",
    "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
    "\n",
    "# findspark.init(\"/content/spark-2.4.5-bin-hadoop2.7\")\n",
    "\n",
    "# BASE_URL = \"./drive/My Drive/Colab Notebooks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:40:20.789080Z",
     "start_time": "2020-05-01T13:40:20.783868Z"
    }
   },
   "source": [
    "# Spark Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:31:31.080241Z",
     "start_time": "2020-05-01T14:31:31.074855Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext, functions as F\n",
    "from pyspark.ml.feature import StopWordsRemover, StringIndexer, Word2Vec, Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.sql.types import (\n",
    "    StringType\n",
    ")\n",
    "from pyspark.ml import PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:40:38.750982Z",
     "start_time": "2020-05-01T13:40:34.456276Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .appName(\"EML Batch 9\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:41:35.957972Z",
     "start_time": "2020-05-01T13:41:29.978810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " category | business                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " text     | \"Record year for Chilean copper Chile's copper industry has registered record earnings of $14.2bn in 2004, the governmental Chilean Copper Commission (Cochilco) has reported. Strong demand from China's fast-growing economy and high prices have fuelled production, said Cochilco vice president Patricio Cartagena. He added that the boom has allowed the government to collect $950m in taxes. Mr Cartagena said the industry expects to see investment worth $10bn over the next three years. \"\"With these investments \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train = spark.read.csv(f\"{BASE_URL}/datasets/train_document.csv\", header=True)\n",
    "# test = spark.read.csv(f\"{BASE_URL}/datasets/test_document.csv\", header=True)\n",
    "train = spark.read.csv(\"./data/train_document.csv\", header=True)\n",
    "test = spark.read.csv(\"./data/test_document.csv\", header=True)\n",
    "train.show(1, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T13:41:48.523110Z",
     "start_time": "2020-05-01T13:41:47.386131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " category     | business                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " text         | \"Record year for Chilean copper Chile's copper industry has registered record earnings of $14.2bn in 2004, the governmental Chilean Copper Commission (Cochilco) has reported. Strong demand from China's fast-growing economy and high prices have fuelled production, said Cochilco vice president Patricio Cartagena. He added that the boom has allowed the government to collect $950m in taxes. Mr Cartagena said the industry expects to see investment worth $10bn over the next three years. \"\"With these investments \n",
      " text_cleaned | \"record year for chilean copper chile's copper industry has registered record earnings of $14.2bn in 2004, the governmental chilean copper commission (cochilco) has reported. strong demand from china's fast-growing economy and high prices have fuelled production, said cochilco vice president patricio cartagena. he added that the boom has allowed the government to collect $950m in taxes. mr cartagena said the industry expects to see investment worth $10bn over the next three years. \"\"with these investments \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@F.udf(returnType=StringType())\n",
    "def preprocessor(x):\n",
    "  x = x.lower()\n",
    "  return x\n",
    "\n",
    "train = train.withColumn(\"text_cleaned\", preprocessor(\"text\"))\n",
    "test = test.withColumn(\"text_cleaned\", preprocessor(\"text\"))\n",
    "\n",
    "train.show(1, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:06:19.698649Z",
     "start_time": "2020-05-01T14:06:19.689234Z"
    }
   },
   "outputs": [],
   "source": [
    "locale = sc._jvm.java.util.Locale\n",
    "locale.setDefault(locale.forLanguageTag(\"en-US\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:06:27.876959Z",
     "start_time": "2020-05-01T14:06:21.444649Z"
    }
   },
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"category\", outputCol=\"categoryIndex\") \n",
    "tokenizer = Tokenizer(inputCol=\"text_cleaned\", outputCol=\"tokenizer_words\")\n",
    "remover = StopWordsRemover(inputCol=\"tokenizer_words\", outputCol=\"filtered_words\")\n",
    "word2Vec = Word2Vec(vectorSize=1, minCount=15, inputCol=\"filtered_words\", outputCol=\"word_vectors\")\n",
    "lr = LogisticRegression(maxIter=1, regParam=0.001, featuresCol = \"word_vectors\", labelCol=\"categoryIndex\")\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, word2Vec, indexer, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to training documents.\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:06:53.468995Z",
     "start_time": "2020-05-01T14:06:53.138175Z"
    }
   },
   "outputs": [],
   "source": [
    "output = model.transform(test)\n",
    "predictionAndLabels = output.rdd.map(lambda x: (x[\"prediction\"], x[\"categoryIndex\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:07:00.617700Z",
     "start_time": "2020-05-01T14:06:59.820754Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:07:06.004827Z",
     "start_time": "2020-05-01T14:07:04.909559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.,  0., 95.,  0.,  0.],\n",
       "       [19., 54., 29.,  0.,  0.],\n",
       "       [ 1.,  0., 83.,  0.,  0.],\n",
       "       [ 9.,  0., 71.,  0.,  0.],\n",
       "       [19.,  6., 52.,  0.,  0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusionMatrix().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:07:11.847042Z",
     "start_time": "2020-05-01T14:07:11.518093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3235955056179775\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {metrics.accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:17:35.449947Z",
     "start_time": "2020-05-01T14:17:35.444980Z"
    }
   },
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01, 0.001]) \\\n",
    "    .addGrid(lr.fitIntercept, [False, True])\\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:20:46.135534Z",
     "start_time": "2020-05-01T14:20:46.127853Z"
    }
   },
   "outputs": [],
   "source": [
    "tvs = TrainValidationSplit(estimator=pipeline,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=MulticlassClassificationEvaluator(labelCol=\"categoryIndex\", metricName=\"accuracy\"),\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:21:13.292974Z",
     "start_time": "2020-05-01T14:20:48.750652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " category        | business             \n",
      " text            | Rank 'set to sell... \n",
      " text_cleaned    | rank 'set to sell... \n",
      " tokenizer_words | [rank, 'set, to, ... \n",
      " filtered_words  | [rank, 'set, sell... \n",
      " word_vectors    | [0.09590236956247... \n",
      " categoryIndex   | 0.0                  \n",
      " rawPrediction   | [0.33299247895591... \n",
      " probability     | [0.24817082173529... \n",
      " prediction      | 2.0                  \n",
      "-RECORD 1-------------------------------\n",
      " category        | business             \n",
      " text            | \"Turkey knocks si... \n",
      " text_cleaned    | \"turkey knocks si... \n",
      " tokenizer_words | [\"turkey, knocks,... \n",
      " filtered_words  | [\"turkey, knocks,... \n",
      " word_vectors    | [0.08278294069611... \n",
      " categoryIndex   | 0.0                  \n",
      " rawPrediction   | [0.30714298564165... \n",
      " probability     | [0.24917775035830... \n",
      " prediction      | 2.0                  \n",
      "-RECORD 2-------------------------------\n",
      " category        | entertainment        \n",
      " text            | \"Early Elvis reco... \n",
      " text_cleaned    | \"early elvis reco... \n",
      " tokenizer_words | [\"early, elvis, r... \n",
      " filtered_words  | [\"early, elvis, r... \n",
      " word_vectors    | [0.08074346154250... \n",
      " categoryIndex   | 4.0                  \n",
      " rawPrediction   | [0.30312455593082... \n",
      " probability     | [0.24923972597693... \n",
      " prediction      | 2.0                  \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run TrainValidationSplit, and choose the best set of parameters.\n",
    "model = tvs.fit(train)\n",
    "\n",
    "# Make predictions on test data. model is the model with combination of parameters\n",
    "# that performed best.\n",
    "model.transform(test)\\\n",
    "    .show(3, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:26:24.686244Z",
     "start_time": "2020-05-01T14:26:24.683025Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:26:35.682895Z",
     "start_time": "2020-05-01T14:26:35.678041Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"model\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:27:28.897849Z",
     "start_time": "2020-05-01T14:27:28.895165Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model = model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:28:17.273288Z",
     "start_time": "2020-05-01T14:28:15.168775Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model.write().overwrite().save(\"model/first_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:31:48.066376Z",
     "start_time": "2020-05-01T14:31:47.255871Z"
    }
   },
   "outputs": [],
   "source": [
    "load_model = PipelineModel.load(\"./model/first_model.pkl/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:32:12.580216Z",
     "start_time": "2020-05-01T14:32:12.368991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------\n",
      " category        | business             \n",
      " text            | Rank 'set to sell... \n",
      " text_cleaned    | rank 'set to sell... \n",
      " tokenizer_words | [rank, 'set, to, ... \n",
      " filtered_words  | [rank, 'set, sell... \n",
      " word_vectors    | [0.09590236956247... \n",
      " categoryIndex   | 0.0                  \n",
      " rawPrediction   | [0.33299247895591... \n",
      " probability     | [0.24817082173529... \n",
      " prediction      | 2.0                  \n",
      "-RECORD 1-------------------------------\n",
      " category        | business             \n",
      " text            | \"Turkey knocks si... \n",
      " text_cleaned    | \"turkey knocks si... \n",
      " tokenizer_words | [\"turkey, knocks,... \n",
      " filtered_words  | [\"turkey, knocks,... \n",
      " word_vectors    | [0.08278294069611... \n",
      " categoryIndex   | 0.0                  \n",
      " rawPrediction   | [0.30714298564165... \n",
      " probability     | [0.24917775035830... \n",
      " prediction      | 2.0                  \n",
      "-RECORD 2-------------------------------\n",
      " category        | entertainment        \n",
      " text            | \"Early Elvis reco... \n",
      " text_cleaned    | \"early elvis reco... \n",
      " tokenizer_words | [\"early, elvis, r... \n",
      " filtered_words  | [\"early, elvis, r... \n",
      " word_vectors    | [0.08074346154250... \n",
      " categoryIndex   | 4.0                  \n",
      " rawPrediction   | [0.30312455593082... \n",
      " probability     | [0.24923972597693... \n",
      " prediction      | 2.0                  \n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_model.transform(test)\\\n",
    "    .show(3, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-01T14:34:21.018373Z",
     "start_time": "2020-05-01T14:34:20.435803Z"
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jcop]",
   "language": "python",
   "name": "conda-env-jcop-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
